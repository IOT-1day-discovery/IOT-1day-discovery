# IOT-1day-discovery

## dependencies
- mongodb
- .net47 (using mono but any 47 will do)
- node 10.12 or above
- Python3

## Initialize Submodule
Follow the [Git Book](https://git-scm.com/book/en/v2/Git-Tools-Submodules#_cloning_submodules) by Scott Chacon and Ben Straub, on how to initilize the submodule:
```sh
cd ./packageparserweb
git submodule init
git submodule update
```

## web crawling
please be courteous to the package repositories. Its really easy to get package explosion.
### Fetching ipks from http://archive.openwrt.org/
the archive has no api so we have to convert html tables to json in the fetchIpks package.
```json
[
    "attitude_adjustment/",
    "backfire/",
    "barrier_breaker/",
    "chaos_calmer/",
    "kamikaze/",
    "releases/",
    "snapshots/"
]
```
Above is an example of what one of the cache files will look like.
Each step of fetchIpks will take a exponentially longer time. which is why caching is so key to that project.
```
downloadAndComputeHashes- > InvokeIpkDownload -> InvokeIpkFetch -> InvokeArchTypes -> 
InvokeArchSetter -> InvokeVersionsSetter -> InvokeCodeNamesSetter
```
from *InvokeIpkFetch* to *InvokeCodeNamesSetter* we are just building up every combination of ipk links we need to download. *InvokeIpkDownload* actually downloads the files.
```
downloadAndComputeHashes- > walkAndComputeHashes -> extractIpk
```
*downloadAndComputeHashes*  uses *walkFs* to walk the filesystem hierarchy and generate a list of every ipk file
downloaded. Then we use extractIpk to decompress and then generate the hash of all the files inside the package.
an Ipk package has the following format:
```
data.tar.gz
control.tar.gz
```
At the end of the run you should see the following files in cache/
- codeNames-cache.json
- archOffsets-cache.json
- archTypes-cache.json
- versionTypes-cache.json
- ipks-cache.json
- ipksha1.json

*ipksha1.json* is imported into the mongodb database using:
-tools/importJsonToMdb.sh

### Fetching and parsing package.gz 
repos used:
- http://archive.debian.org/debian/dists/
- http://archive.openwrt.org/
- http://cz.archive.ubuntu.com/ubuntu/dists/
- https://archive.raspbian.org/raspbian/dists/

*fetchPackages.js* has been specialized for each of these distros to pull down package.gz  files.
While we are no longer using this for package retrieval, the version info stored within is very helpful
for retreiving version number in a reiliable fashion. something we need for the cve poriton of the project.
In any case PackageParserCLI has been written to decompress each package.gz fetched by fetchPackages.js parse them into a json and store them into the database.

## parsing files generated by iotfw-tool
This project has  crawled:
-Different file systems:  958
-Unique binary names: 6399
-Unique binary hashes: 18,6373
Sufficed to say every parse job is very time consuming and we want to limit that.
*FindUniquePackages* reads in filesystem.execfiles_detailed.csv.xz files and generates
a JSON file that we feed into mongodb
```json
{
    "name": "airlink_app",
    "files": [
        {
            "filepath": "360/_325bcc38de186d7d96b85839c5696e99b3b42c6f.bin.extracted/filesystem/app/airlink_app/bin/airlink_app",
            "sha1": "0d68987d77b50263e83a64d887a23143ac8f81d3"
        },
        {
            "filepath": "360/_4eacbe421bf35935f5321678d3e677331b5a3027.bin.extracted/filesystem/app/airlink_app/bin/airlink_app",
            "sha1": "b77509dd073ac37453edbf98b2c9ba6d1024734a"
        },
        {
            "filepath": "360/_b84bdd67acc6005eca232a82c3bd97a13b051de0.bin.extracted/filesystem/app/airlink_app/bin/airlink_app",
            "sha1": "2c61d8d13c24360d86cafda5c9c914e0817e25bd"
        }
    ]
}
```
This ordering lists all the unique versions of a given binary name and the file path it was found on.
This ordering reduces the number of files we have to check our db against. this reduces our file size to
39.5 MB vs 251.6 MB that it would have been if we kept all duplicate sha records. thats an 84.3% space savings.

## web frontend
This is more of a database nicesty as making http requests is easier than making mongodb requests.
- run by calling *launch.sh*
### API Documentation
#### GET binary/sha1/<hash>
- [x] fetches binaries associated with this sha.
#### GET binary/<name>
- [ ] fetches binaries associated with this name. (in progress)
#### GET /sha1/<hash>
- [x] fetches packages associated with this hash
#### GET /sha256/<hash> 
- [x] fetches packages associated with this hash
#### GET /md5/<hash>
- [x] fetches packages associated with this hash